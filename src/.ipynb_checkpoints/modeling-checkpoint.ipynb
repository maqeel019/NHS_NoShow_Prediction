{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f923f853-ce12-4da1-8ee4-0cceffda8a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMD_Decile</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Age_Group</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Medical_Specialty</th>\n",
       "      <th>Consultation_Type</th>\n",
       "      <th>Appointment_Type</th>\n",
       "      <th>Base_NoShow_Prob</th>\n",
       "      <th>NoShow_Prob_Final</th>\n",
       "      <th>Previous_Appointments</th>\n",
       "      <th>Previous_NoShows</th>\n",
       "      <th>NoShow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>More deprived 30-40%</td>\n",
       "      <td>Pakistani (Asian or Asian British)</td>\n",
       "      <td>45-49</td>\n",
       "      <td>Female</td>\n",
       "      <td>Trauma and Orthopaedics</td>\n",
       "      <td>Face-to-Face</td>\n",
       "      <td>Subsequent</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.029</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Least deprived 10%</td>\n",
       "      <td>British (White)</td>\n",
       "      <td>90-120</td>\n",
       "      <td>Female</td>\n",
       "      <td>Allied Health Professional</td>\n",
       "      <td>Face-to-Face</td>\n",
       "      <td>Subsequent</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.011</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Less deprived 20-30%</td>\n",
       "      <td>British (White)</td>\n",
       "      <td>65-69</td>\n",
       "      <td>Female</td>\n",
       "      <td>Cardiology</td>\n",
       "      <td>Face-to-Face</td>\n",
       "      <td>Subsequent</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.021</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Less deprived 30-40%</td>\n",
       "      <td>British (White)</td>\n",
       "      <td>10-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>Paediatrics</td>\n",
       "      <td>Face-to-Face</td>\n",
       "      <td>First</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.099</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>More deprived 10-20%</td>\n",
       "      <td>British (White)</td>\n",
       "      <td>85-89</td>\n",
       "      <td>Female</td>\n",
       "      <td>General Surgery</td>\n",
       "      <td>Face-to-Face</td>\n",
       "      <td>Subsequent</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.013</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>More deprived 30-40%</td>\n",
       "      <td>Any other White background</td>\n",
       "      <td>85-89</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ophthalmology</td>\n",
       "      <td>Face-to-Face</td>\n",
       "      <td>Subsequent</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.023</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>Most deprived 10%</td>\n",
       "      <td>British (White)</td>\n",
       "      <td>17</td>\n",
       "      <td>Male</td>\n",
       "      <td>Urology</td>\n",
       "      <td>Face-to-Face</td>\n",
       "      <td>Subsequent</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.053</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>More deprived 10-20%</td>\n",
       "      <td>British (White)</td>\n",
       "      <td>60-64</td>\n",
       "      <td>Female</td>\n",
       "      <td>Gynaecology</td>\n",
       "      <td>Face-to-Face</td>\n",
       "      <td>Subsequent</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.023</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>Most deprived 10%</td>\n",
       "      <td>Chinese (other ethnic group)</td>\n",
       "      <td>50-54</td>\n",
       "      <td>Female</td>\n",
       "      <td>Nursing</td>\n",
       "      <td>Face-to-Face</td>\n",
       "      <td>Subsequent</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.027</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>More deprived 20-30%</td>\n",
       "      <td>British (White)</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Paediatrics</td>\n",
       "      <td>Face-to-Face</td>\n",
       "      <td>Subsequent</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.065</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  IMD_Decile                           Ethnicity Age_Group  \\\n",
       "0       More deprived 30-40%  Pakistani (Asian or Asian British)     45-49   \n",
       "1         Least deprived 10%                     British (White)    90-120   \n",
       "2       Less deprived 20-30%                     British (White)     65-69   \n",
       "3       Less deprived 30-40%                     British (White)     10-14   \n",
       "4       More deprived 10-20%                     British (White)     85-89   \n",
       "...                      ...                                 ...       ...   \n",
       "249995  More deprived 30-40%          Any other White background     85-89   \n",
       "249996     Most deprived 10%                     British (White)        17   \n",
       "249997  More deprived 10-20%                     British (White)     60-64   \n",
       "249998     Most deprived 10%        Chinese (other ethnic group)     50-54   \n",
       "249999  More deprived 20-30%                     British (White)         0   \n",
       "\n",
       "        Gender           Medical_Specialty Consultation_Type Appointment_Type  \\\n",
       "0       Female     Trauma and Orthopaedics      Face-to-Face       Subsequent   \n",
       "1       Female  Allied Health Professional      Face-to-Face       Subsequent   \n",
       "2       Female                  Cardiology      Face-to-Face       Subsequent   \n",
       "3         Male                 Paediatrics      Face-to-Face            First   \n",
       "4       Female             General Surgery      Face-to-Face       Subsequent   \n",
       "...        ...                         ...               ...              ...   \n",
       "249995    Male               Ophthalmology      Face-to-Face       Subsequent   \n",
       "249996    Male                     Urology      Face-to-Face       Subsequent   \n",
       "249997  Female                 Gynaecology      Face-to-Face       Subsequent   \n",
       "249998  Female                     Nursing      Face-to-Face       Subsequent   \n",
       "249999    Male                 Paediatrics      Face-to-Face       Subsequent   \n",
       "\n",
       "        Base_NoShow_Prob  NoShow_Prob_Final  Previous_Appointments  \\\n",
       "0                   0.01              0.029                      2   \n",
       "1                   0.01              0.011                      5   \n",
       "2                   0.01              0.021                      4   \n",
       "3                   0.01              0.099                      5   \n",
       "4                   0.01              0.013                      4   \n",
       "...                  ...                ...                    ...   \n",
       "249995              0.01              0.023                      2   \n",
       "249996              0.01              0.053                      6   \n",
       "249997              0.01              0.023                      4   \n",
       "249998              0.01              0.027                      5   \n",
       "249999              0.01              0.065                      2   \n",
       "\n",
       "        Previous_NoShows NoShow  \n",
       "0                      0     No  \n",
       "1                      0     No  \n",
       "2                      0     No  \n",
       "3                      0     No  \n",
       "4                      0     No  \n",
       "...                  ...    ...  \n",
       "249995                 0     No  \n",
       "249996                 0     No  \n",
       "249997                 0     No  \n",
       "249998                 0     No  \n",
       "249999                 0     No  \n",
       "\n",
       "[250000 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "\n",
    "# Load dataset \n",
    "df = pd.read_csv(\"../data/processed/nhs_no_show_enhanced_synthetic.csv\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67bee928-8696-41ac-9989-25bcc6439a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250000 entries, 0 to 249999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   IMD_Decile             250000 non-null  object \n",
      " 1   Ethnicity              250000 non-null  object \n",
      " 2   Age_Group              250000 non-null  object \n",
      " 3   Gender                 250000 non-null  object \n",
      " 4   Medical_Specialty      250000 non-null  object \n",
      " 5   Consultation_Type      250000 non-null  object \n",
      " 6   Appointment_Type       250000 non-null  object \n",
      " 7   Base_NoShow_Prob       250000 non-null  float64\n",
      " 8   NoShow_Prob_Final      250000 non-null  float64\n",
      " 9   Previous_Appointments  250000 non-null  int64  \n",
      " 10  Previous_NoShows       250000 non-null  int64  \n",
      " 11  NoShow                 250000 non-null  object \n",
      "dtypes: float64(2), int64(2), object(8)\n",
      "memory usage: 22.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base_NoShow_Prob</th>\n",
       "      <th>NoShow_Prob_Final</th>\n",
       "      <th>Previous_Appointments</th>\n",
       "      <th>Previous_NoShows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.039792</td>\n",
       "      <td>3.495700</td>\n",
       "      <td>0.138812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.259378e-14</td>\n",
       "      <td>0.022651</td>\n",
       "      <td>1.872326</td>\n",
       "      <td>0.380820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Base_NoShow_Prob  NoShow_Prob_Final  Previous_Appointments  \\\n",
       "count      2.500000e+05      250000.000000          250000.000000   \n",
       "mean       1.000000e-02           0.039792               3.495700   \n",
       "std        3.259378e-14           0.022651               1.872326   \n",
       "min        1.000000e-02           0.010000               0.000000   \n",
       "25%        1.000000e-02           0.023000               2.000000   \n",
       "50%        1.000000e-02           0.033000               3.000000   \n",
       "75%        1.000000e-02           0.059000               5.000000   \n",
       "max        1.000000e-02           0.105000              17.000000   \n",
       "\n",
       "       Previous_NoShows  \n",
       "count     250000.000000  \n",
       "mean           0.138812  \n",
       "std            0.380820  \n",
       "min            0.000000  \n",
       "25%            0.000000  \n",
       "50%            0.000000  \n",
       "75%            0.000000  \n",
       "max            5.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "577d68de-9576-41b5-80c1-6817ab41e90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "Duplicates before: 63476\n",
      "Duplicates after: 0\n",
      "******************************\n",
      "IMD_Decile               0\n",
      "Ethnicity                0\n",
      "Age_Group                0\n",
      "Gender                   0\n",
      "Medical_Specialty        0\n",
      "Consultation_Type        0\n",
      "Appointment_Type         0\n",
      "Base_NoShow_Prob         0\n",
      "NoShow_Prob_Final        0\n",
      "Previous_Appointments    0\n",
      "Previous_NoShows         0\n",
      "NoShow                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# droping duplicate data\n",
    "print(\"*\"*30)\n",
    "print(\"Duplicates before:\", df.duplicated().sum())\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "print(\"Duplicates after:\", df.duplicated().sum())\n",
    "print(\"*\"*30)\n",
    "\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "746cab4f-6edd-4a91-9858-0ded2e824fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No' 'Yes']\n",
      "['Pakistani (Asian or Asian British)' 'British (White)'\n",
      " 'Indian (Asian or Asian British)' 'Caribbean (Black or Black British)'\n",
      " 'African (Black or Black British)' 'Any other Black background'\n",
      " 'Not Known' 'Any other White background' 'Any other Mixed background'\n",
      " 'Irish (White)' 'Any other ethnic group' 'Any other Asian background'\n",
      " 'Bangladeshi (Asian or Asian British)' 'White and Asian (Mixed)'\n",
      " 'White and Black Caribbean (Mixed)' 'White and Black African (Mixed)'\n",
      " 'Chinese (other ethnic group)']\n",
      "['45-49' '90-120' '65-69' '10-14' '85-89' '5-9' '25-29' '35-39' '80-84'\n",
      " '40-44' '30-34' '55-59' '60-64' '70-74' '75-79' '1-4' '50-54' '0' '20-24'\n",
      " '18' 'Unknown' '17' '15' '16']\n",
      "['Female' 'Male']\n",
      "['Trauma and Orthopaedics' 'Allied Health Professional' 'Cardiology'\n",
      " 'Paediatrics' 'General Surgery' 'Medical Oncology' 'Dermatology'\n",
      " 'Paediatric Dentistry' 'Adult Mental Illness' 'Ear Nose and Throat'\n",
      " 'Nursing' 'Gynaecology' 'Gastroenterology' 'Radiology' 'Anaesthetics'\n",
      " 'Obstetrics' 'Infectious Diseases' 'Rehabilitation Medicine' 'Urology'\n",
      " 'Clinical Oncology' 'Neurology' 'Ophthalmology' 'Respiratory Medicine'\n",
      " 'Paediatric Cardiology' 'Orthodontics' 'Midwifery'\n",
      " 'General Internal Medicine' 'Community Medicine' 'Neurosurgery'\n",
      " 'Medical Ophthalmology' 'Rheumatology' 'Not Known'\n",
      " 'Child and Adolescent Psychiatry' 'Renal Medicine'\n",
      " 'Cardiothoracic Surgery' 'Clinical Haematology' 'Acute Internal Medicine'\n",
      " 'Genitourinary Medicine' 'Palliative Medicine' 'Clinical Physiology'\n",
      " 'Plastic Surgery' 'Restorative Dentistry' 'Emergency Medicine'\n",
      " 'Clinical Neurophysiology' 'Geriatric Medicine' 'Oral Surgery'\n",
      " 'Dental Medicine' 'Endocrinology and Diabetes' 'Haematology'\n",
      " 'Audio Vestibular Medicine' 'Learning Disability'\n",
      " 'Oral and Maxillofacial Surgery' 'Chemical Pathology'\n",
      " 'Clinical Pharmacology' 'Endodontics' 'Paediatric Surgery'\n",
      " 'General Medical Practice' 'Histopathology' 'Old Age Psychiatry'\n",
      " 'Sport and Exercise Medicine' 'Clinical Genetics'\n",
      " 'General Dental Practice' 'Clinical Immunology' 'Vascular Surgery'\n",
      " 'Intensive Care Medicine' 'Nuclear Medicine'\n",
      " 'Medical Microbiology and Virology' 'Medical Psychotherapy'\n",
      " 'Forensic Psychiatry' 'Paediatric Neurology' 'Occupational Medicine'\n",
      " 'Special Care Dentistry' 'Allergy' 'Community Health Services Dental'\n",
      " 'Joint Consultant Clinics (Retired 1 April 2004)' 'Prosthodontics'\n",
      " 'Medical Microbiology' 'Periodontics' 'Public Health Medicine'\n",
      " 'Medical Virology' 'Immunopathology' 'General Pathology']\n",
      "['Face-to-Face' 'tele-consult']\n",
      "['Subsequent' 'First']\n",
      "[ 2  5  4  3  6  8  7  0  1  9 11 12 10 13 14 15 17]\n",
      "[0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "print(df['NoShow'].unique())\n",
    "print(df['Ethnicity'].unique())\n",
    "print(df['Age_Group'].unique())\n",
    "print(df['Gender'].unique())\n",
    "print(df['Medical_Specialty'].unique())\n",
    "print(df['Consultation_Type'].unique())\n",
    "print(df['Appointment_Type'].unique())\n",
    "print(df['Previous_Appointments'].unique())\n",
    "print(df['Previous_NoShows'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "910c19a8-7cdc-4fc4-81b9-47dc71f92303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMD_Decile</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Age_Group</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Medical_Specialty</th>\n",
       "      <th>Consultation_Type</th>\n",
       "      <th>Appointment_Type</th>\n",
       "      <th>Previous_Appointments</th>\n",
       "      <th>Previous_NoShows</th>\n",
       "      <th>NoShow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>More deprived 30-40%</td>\n",
       "      <td>Pakistani (Asian or Asian British)</td>\n",
       "      <td>45-49</td>\n",
       "      <td>Female</td>\n",
       "      <td>Trauma and Orthopaedics</td>\n",
       "      <td>Face-to-Face</td>\n",
       "      <td>Subsequent</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Least deprived 10%</td>\n",
       "      <td>British (White)</td>\n",
       "      <td>90-120</td>\n",
       "      <td>Female</td>\n",
       "      <td>Allied Health Professional</td>\n",
       "      <td>Face-to-Face</td>\n",
       "      <td>Subsequent</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Less deprived 20-30%</td>\n",
       "      <td>British (White)</td>\n",
       "      <td>65-69</td>\n",
       "      <td>Female</td>\n",
       "      <td>Cardiology</td>\n",
       "      <td>Face-to-Face</td>\n",
       "      <td>Subsequent</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Less deprived 30-40%</td>\n",
       "      <td>British (White)</td>\n",
       "      <td>10-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>Paediatrics</td>\n",
       "      <td>Face-to-Face</td>\n",
       "      <td>First</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>More deprived 10-20%</td>\n",
       "      <td>British (White)</td>\n",
       "      <td>85-89</td>\n",
       "      <td>Female</td>\n",
       "      <td>General Surgery</td>\n",
       "      <td>Face-to-Face</td>\n",
       "      <td>Subsequent</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186519</th>\n",
       "      <td>Unknown/Non-UK Country</td>\n",
       "      <td>British (White)</td>\n",
       "      <td>90-120</td>\n",
       "      <td>Male</td>\n",
       "      <td>Plastic Surgery</td>\n",
       "      <td>Face-to-Face</td>\n",
       "      <td>Subsequent</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186520</th>\n",
       "      <td>Most deprived 10%</td>\n",
       "      <td>Any other ethnic group</td>\n",
       "      <td>60-64</td>\n",
       "      <td>Female</td>\n",
       "      <td>Ophthalmology</td>\n",
       "      <td>Face-to-Face</td>\n",
       "      <td>First</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186521</th>\n",
       "      <td>Most deprived 10%</td>\n",
       "      <td>British (White)</td>\n",
       "      <td>17</td>\n",
       "      <td>Male</td>\n",
       "      <td>Urology</td>\n",
       "      <td>Face-to-Face</td>\n",
       "      <td>Subsequent</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186522</th>\n",
       "      <td>Most deprived 10%</td>\n",
       "      <td>Chinese (other ethnic group)</td>\n",
       "      <td>50-54</td>\n",
       "      <td>Female</td>\n",
       "      <td>Nursing</td>\n",
       "      <td>Face-to-Face</td>\n",
       "      <td>Subsequent</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186523</th>\n",
       "      <td>More deprived 20-30%</td>\n",
       "      <td>British (White)</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Paediatrics</td>\n",
       "      <td>Face-to-Face</td>\n",
       "      <td>Subsequent</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186524 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    IMD_Decile                           Ethnicity Age_Group  \\\n",
       "0         More deprived 30-40%  Pakistani (Asian or Asian British)     45-49   \n",
       "1           Least deprived 10%                     British (White)    90-120   \n",
       "2         Less deprived 20-30%                     British (White)     65-69   \n",
       "3         Less deprived 30-40%                     British (White)     10-14   \n",
       "4         More deprived 10-20%                     British (White)     85-89   \n",
       "...                        ...                                 ...       ...   \n",
       "186519  Unknown/Non-UK Country                     British (White)    90-120   \n",
       "186520       Most deprived 10%              Any other ethnic group     60-64   \n",
       "186521       Most deprived 10%                     British (White)        17   \n",
       "186522       Most deprived 10%        Chinese (other ethnic group)     50-54   \n",
       "186523    More deprived 20-30%                     British (White)         0   \n",
       "\n",
       "        Gender           Medical_Specialty Consultation_Type Appointment_Type  \\\n",
       "0       Female     Trauma and Orthopaedics      Face-to-Face       Subsequent   \n",
       "1       Female  Allied Health Professional      Face-to-Face       Subsequent   \n",
       "2       Female                  Cardiology      Face-to-Face       Subsequent   \n",
       "3         Male                 Paediatrics      Face-to-Face            First   \n",
       "4       Female             General Surgery      Face-to-Face       Subsequent   \n",
       "...        ...                         ...               ...              ...   \n",
       "186519    Male             Plastic Surgery      Face-to-Face       Subsequent   \n",
       "186520  Female               Ophthalmology      Face-to-Face            First   \n",
       "186521    Male                     Urology      Face-to-Face       Subsequent   \n",
       "186522  Female                     Nursing      Face-to-Face       Subsequent   \n",
       "186523    Male                 Paediatrics      Face-to-Face       Subsequent   \n",
       "\n",
       "        Previous_Appointments  Previous_NoShows NoShow  \n",
       "0                           2                 0     No  \n",
       "1                           5                 0     No  \n",
       "2                           4                 0     No  \n",
       "3                           5                 0     No  \n",
       "4                           4                 0     No  \n",
       "...                       ...               ...    ...  \n",
       "186519                      3                 0     No  \n",
       "186520                      3                 0     No  \n",
       "186521                      6                 0     No  \n",
       "186522                      5                 0     No  \n",
       "186523                      2                 0     No  \n",
       "\n",
       "[186524 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping Base_NoShow_Prob and NoShow_Prob_Final because they are derived from other features. \n",
    "# Including them could give the model a hint and lead to overfitting.\n",
    "\n",
    "df.drop(columns = [\"Base_NoShow_Prob\" , \"NoShow_Prob_Final\"] , inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33cdbe9e-ae1a-4e09-bfcf-075a788fe0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 186524 entries, 0 to 186523\n",
      "Data columns (total 11 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   IMD_Decile             186524 non-null  object \n",
      " 1   Ethnicity              186524 non-null  object \n",
      " 2   Age_Group              186524 non-null  object \n",
      " 3   Gender                 186524 non-null  object \n",
      " 4   Medical_Specialty      186524 non-null  object \n",
      " 5   Consultation_Type      186524 non-null  object \n",
      " 6   Appointment_Type       186524 non-null  object \n",
      " 7   Previous_Appointments  186524 non-null  int64  \n",
      " 8   Previous_NoShows       186524 non-null  int64  \n",
      " 9   NoShow                 186524 non-null  object \n",
      " 10  NoShowRate             186524 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 15.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Creating New feature\n",
    "df[\"NoShowRate\"] = df[\"Previous_NoShows\"] / np.where(df[\"Previous_Appointments\"] == 0, 1, df[\"Previous_Appointments\"])\n",
    "\n",
    "df[\"NoShowRate\"] = df[\"NoShowRate\"].round(3)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e0fbe03-9968-4f32-9c5c-57d9cde36aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# NoShow currently \"Yes\"/\"No\" — convert to 1/0\n",
    "df['NoShow'] = df['NoShow'].map({'Yes': 1, 'No': 0})\n",
    "df['NoShow'] = df['NoShow'].astype(int)\n",
    "\n",
    "# Simple label encoding\n",
    "le_imd = LabelEncoder()\n",
    "df['IMD_encoded'] = le_imd.fit_transform(df['IMD_Decile'].astype(str))\n",
    "\n",
    "# Replacing each specialty with its relative frequency (0..1)\n",
    "specialty_counts = df['Medical_Specialty'].value_counts(normalize=True)\n",
    "df['Specialty_Freq'] = df['Medical_Specialty'].map(specialty_counts)\n",
    "\n",
    "# D. One-hot encode other categorical columns\n",
    "one_hot_cols = ['Ethnicity', 'Age_Group', 'Gender', 'Consultation_Type', 'Appointment_Type']\n",
    "\n",
    "# Use get_dummies; drop_first=True to avoid perfect multicollinearity (optional)\n",
    "df_encoded = pd.get_dummies(df, columns=one_hot_cols, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89713873-6173-42e2-8821-5706647faf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded feature shape: (186524, 47)\n",
      "Sample feature columns: ['IMD_encoded', 'Specialty_Freq', 'Previous_Appointments', 'Previous_NoShows', 'NoShowRate', 'Ethnicity_Any other Asian background', 'Ethnicity_Any other Black background', 'Ethnicity_Any other Mixed background', 'Ethnicity_Any other White background', 'Ethnicity_Any other ethnic group', 'Ethnicity_Bangladeshi (Asian or Asian British)', 'Ethnicity_British (White)', 'Ethnicity_Caribbean (Black or Black British)', 'Ethnicity_Chinese (other ethnic group)', 'Ethnicity_Indian (Asian or Asian British)', 'Ethnicity_Irish (White)', 'Ethnicity_Not Known', 'Ethnicity_Pakistani (Asian or Asian British)', 'Ethnicity_White and Asian (Mixed)', 'Ethnicity_White and Black African (Mixed)']\n",
      "Target distribution:\n",
      " NoShow\n",
      "0    0.947438\n",
      "1    0.052562\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Final feature list\n",
    "\n",
    "features = [\n",
    "    'IMD_encoded',\n",
    "    'Specialty_Freq',\n",
    "    'Previous_Appointments',\n",
    "    'Previous_NoShows',\n",
    "    'NoShowRate'\n",
    "]\n",
    "# add all generated one-hot columns\n",
    "one_hot_generated = [c for c in df_encoded.columns if any(c.startswith(col + '_') for col in one_hot_cols)]\n",
    "features += one_hot_generated\n",
    "\n",
    "X = df_encoded[features]\n",
    "y = df_encoded['NoShow']\n",
    "\n",
    "\n",
    "print(\"Encoded feature shape:\", X.shape)\n",
    "print(\"Sample feature columns:\", X.columns[:20].tolist())\n",
    "print(\"Target distribution:\\n\", y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1819ffc-ae0b-42b4-b59c-1aa125cefe68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (139893, 47)\n",
      "Test set shape: (46631, 47)\n",
      "Training target distribution:\n",
      " NoShow\n",
      "0    0.947438\n",
      "1    0.052562\n",
      "Name: proportion, dtype: float64\n",
      "Test target distribution:\n",
      " NoShow\n",
      "0    0.947438\n",
      "1    0.052562\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Using 75% data for training and 25% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)\n",
    "print(\"Training target distribution:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"Test target distribution:\\n\", y_test.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffb2bd75-a848-436e-94b4-c1f2521b9d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest training completed!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,         # number of trees\n",
    "    max_depth=None,           # let trees grow fully\n",
    "    random_state=42,\n",
    "    class_weight='balanced',  # automatically adjust for class imbalance\n",
    "    n_jobs=-1                 # use all CPU cores for speed\n",
    ")\n",
    "\n",
    "# training model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Random Forest training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "564a7ab1-002d-452f-8308-f8c085defb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.932\n",
      "F1 Score: 0.0019\n",
      "ROC AUC: 0.5439\n",
      "\n",
      "Confusion Matrix:\n",
      " [[43456   724]\n",
      " [ 2448     3]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96     44180\n",
      "           1       0.00      0.00      0.00      2451\n",
      "\n",
      "    accuracy                           0.93     46631\n",
      "   macro avg       0.48      0.49      0.48     46631\n",
      "weighted avg       0.90      0.93      0.91     46631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report, roc_auc_score, RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make predictions \n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_pred_prob = rf_model.predict_proba(X_test)[:, 1]  # probability for class 1 (NoShow)\n",
    "\n",
    "# performance\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", round(acc, 4))\n",
    "print(\"F1 Score:\", round(f1, 4))\n",
    "print(\"ROC AUC:\", round(roc_auc, 4))\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc6c5fcd-b347-4f75-abae-55e5698577a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logistic Regression \n",
      "Accuracy: 0.622\n",
      "F1 Score: 0.1466\n",
      "ROC AUC: 0.6627\n",
      "\n",
      "Confusion Matrix:\n",
      " [[27492 16688]\n",
      " [  937  1514]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.62      0.76     44180\n",
      "           1       0.08      0.62      0.15      2451\n",
      "\n",
      "    accuracy                           0.62     46631\n",
      "   macro avg       0.53      0.62      0.45     46631\n",
      "weighted avg       0.92      0.62      0.73     46631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "# Model\n",
    "lr = LogisticRegression(\n",
    "    class_weight='balanced',  # handle imbalance\n",
    "    max_iter=1000,            # ensure convergence\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "y_prob_lr = lr.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Evaluate\n",
    "acc = accuracy_score(y_test, y_pred_lr)\n",
    "f1 = f1_score(y_test, y_pred_lr)\n",
    "roc_auc = roc_auc_score(y_test, y_prob_lr)\n",
    "cm = confusion_matrix(y_test, y_pred_lr)\n",
    "\n",
    "print(\" Logistic Regression \")\n",
    "print(\"Accuracy:\", round(acc, 4))\n",
    "print(\"F1 Score:\", round(f1, 4))\n",
    "print(\"ROC AUC:\", round(roc_auc, 4))\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07abdfe4-04ae-4e2a-b5d8-db67bb46dbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 7353, number of negative: 132540\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 220\n",
      "[LightGBM] [Info] Number of data points in the train set: 139893, number of used features: 47\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      " LightGBM \n",
      "Accuracy: 0.6226\n",
      "F1 Score: 0.1466\n",
      "ROC AUC: 0.6609\n",
      "\n",
      "Confusion Matrix:\n",
      " [[27521 16659]\n",
      " [  939  1512]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.62      0.76     44180\n",
      "           1       0.08      0.62      0.15      2451\n",
      "\n",
      "    accuracy                           0.62     46631\n",
      "   macro avg       0.53      0.62      0.45     46631\n",
      "weighted avg       0.92      0.62      0.73     46631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Handle imbalance using scale_pos_weight\n",
    "pos = y_train.sum()\n",
    "neg = len(y_train) - pos\n",
    "scale = neg / pos\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary',\n",
    "    class_weight='balanced',  # alternative to scale_pos_weight\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "y_prob_lgb = lgb_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Evaluate\n",
    "acc = accuracy_score(y_test, y_pred_lgb)\n",
    "f1 = f1_score(y_test, y_pred_lgb)\n",
    "roc_auc = roc_auc_score(y_test, y_prob_lgb)\n",
    "cm = confusion_matrix(y_test, y_pred_lgb)\n",
    "\n",
    "print(\" LightGBM \")\n",
    "print(\"Accuracy:\", round(acc, 4))\n",
    "print(\"F1 Score:\", round(f1, 4))\n",
    "print(\"ROC AUC:\", round(roc_auc, 4))\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_lgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6ccf16f-878b-461a-b6a8-3e90b7511f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight = 18.025295797633618\n",
      "XGBoost training completed!\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# count ratio for weight\n",
    "pos = y_train.sum()\n",
    "neg = len(y_train) - pos\n",
    "scale = neg / pos\n",
    "print(\"scale_pos_weight =\", scale)\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    scale_pos_weight=scale,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "print(\"XGBoost training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dc5d474-7066-48fc-b307-2d679c0c8284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.61\n",
      "Best F1 at that threshold: 0.1585\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "best_thr = 0\n",
    "best_f1 = 0\n",
    "y_prob = xgb.predict_proba(X_test)[:,1]\n",
    "\n",
    "for thr in np.arange(0.05, 0.90, 0.01):\n",
    "    y_pred_thr = (y_prob >= thr).astype(int)\n",
    "    f1 = f1_score(y_test, y_pred_thr)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thr = thr\n",
    "\n",
    "print(\"Best threshold:\", round(best_thr, 3))\n",
    "print(\"Best F1 at that threshold:\", round(best_f1, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c2abb1e-b7aa-4ad0-b064-ef984f3c7feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold used: 0.6\n",
      "Accuracy: 0.797\n",
      "F1 Score: 0.1568\n",
      "ROC AUC: 0.6601\n",
      "\n",
      "Confusion Matrix:\n",
      " [[36286  7894]\n",
      " [ 1571   880]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.82      0.88     44180\n",
      "           1       0.10      0.36      0.16      2451\n",
      "\n",
      "    accuracy                           0.80     46631\n",
      "   macro avg       0.53      0.59      0.52     46631\n",
      "weighted avg       0.91      0.80      0.85     46631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, accuracy_score\n",
    "\n",
    "thr = 0.60\n",
    "\n",
    "y_pred_opt = (xgb.predict_proba(X_test)[:,1] >= thr).astype(int)\n",
    "\n",
    "print(\"Threshold used:\", thr)\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test, y_pred_opt), 4))\n",
    "print(\"F1 Score:\", round(f1_score(y_test, y_pred_opt), 4))\n",
    "print(\"ROC AUC:\", round(roc_auc_score(y_test, xgb.predict_proba(X_test)[:,1]), 4))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_opt))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_opt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e7c07f8-627d-4833-a9bc-ede2bbe6bf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Base model\n",
    "xgb = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    scale_pos_weight = (len(y_train) - y_train.sum()) / y_train.sum(), \n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "\n",
    "# Hyperparameter grid for random search\n",
    "param_dist = {\n",
    "    'n_estimators': [200, 400, 600],\n",
    "    'max_depth': [3, 5, 6, 8],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.3],\n",
    "    'reg_alpha': [0, 0.01, 0.1],\n",
    "    'reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV\n",
    "xgb_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=25,          # number of random combinations to try\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "180a5a9c-81cf-4767-a727-b4885a3881de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "Best hyperparameters found: {'subsample': 0.9, 'reg_lambda': 2, 'reg_alpha': 0.1, 'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.05, 'gamma': 0.3, 'colsample_bytree': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Fit on training data\n",
    "xgb_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from search\n",
    "xgb_best = xgb_search.best_estimator_\n",
    "\n",
    "print(\"Best hyperparameters found:\", xgb_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88384211-43a5-47e9-bba3-0f9b493ae188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.596\n",
      "Best F1 at that threshold: 0.1592\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_prob = xgb_best.predict_proba(X_test)[:,1]\n",
    "\n",
    "best_thr = 0\n",
    "best_f1 = 0\n",
    "\n",
    "for thr in np.arange(0.01, 0.90, 0.002):\n",
    "    y_pred_thr = (y_prob >= thr).astype(int)\n",
    "    f1 = f1_score(y_test, y_pred_thr)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thr = thr\n",
    "\n",
    "print(\"Best threshold:\", round(best_thr, 3))\n",
    "print(\"Best F1 at that threshold:\", round(best_f1, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a2b6dca-75d2-4a17-b491-ddebad4bd276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold used: 0.596\n",
      "Accuracy: 0.8036\n",
      "F1 Score: 0.1592\n",
      "ROC AUC: 0.6571\n",
      "\n",
      "Confusion Matrix:\n",
      " [[36606  7574]\n",
      " [ 1584   867]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89     44180\n",
      "           1       0.10      0.35      0.16      2451\n",
      "\n",
      "    accuracy                           0.80     46631\n",
      "   macro avg       0.53      0.59      0.52     46631\n",
      "weighted avg       0.91      0.80      0.85     46631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predictions using optimal threshold\n",
    "y_pred_opt = (y_prob >= best_thr).astype(int)\n",
    "\n",
    "print(\"Threshold used:\", best_thr)\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test, y_pred_opt), 4))\n",
    "print(\"F1 Score:\", round(f1_score(y_test, y_pred_opt), 4))\n",
    "print(\"ROC AUC:\", round(roc_auc_score(y_test, y_prob), 4))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_opt))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_opt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d2af6a6-f41b-46b0-a488-1827fc3294ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save fitted preprocessor + model + threshold\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[1;32m      3\u001b[0m pipeline_data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: xgb_best,  \u001b[38;5;66;03m# Your tuned model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m: preprocessor,  \u001b[38;5;66;03m# Fitted one!\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthreshold\u001b[39m\u001b[38;5;124m'\u001b[39m: best_thr  \u001b[38;5;66;03m# From your loop\u001b[39;00m\n\u001b[1;32m      7\u001b[0m }\n\u001b[1;32m      8\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(pipeline_data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgb_pipeline.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Single file, repo root\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitted pipeline saved—exact match for app!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocessor' is not defined"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(xgb_best, '../xgb_model.joblib')  # Better filename; saves in repo root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21f973d2-0e7d-40a4-aee5-e690bf44296d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook XGBoost version: 3.1.1\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "print('Notebook XGBoost version:', xgboost.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
